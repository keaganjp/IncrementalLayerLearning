{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMkHNLRLcBkF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from math import floor\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AThE8rqb0Gvk"
      },
      "outputs": [],
      "source": [
        "# The new version of FF - every layer has an untrainable predictor layer\n",
        "# We train layer by layer\n",
        "\n",
        "# The basic linear layer\n",
        "class FFLinearLayer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, layer_lr = 0.001,\n",
        "                 num_classes = 10, num_epochs = 25,\n",
        "                 bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.opt = Adam(self.parameters(), lr=layer_lr)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.predictor = nn.Linear(out_features, num_classes, device=device)\n",
        "        self.predictor.requires_grad = False\n",
        "    \n",
        "    def forward(self, x):\n",
        "        layerOutput = self.relu(super().forward(x))\n",
        "        predictorOutput = self.predictor.forward(layerOutput)\n",
        "        return layerOutput, predictorOutput\n",
        "    \n",
        "    def predict(self, x):\n",
        "        layerOutput, predictorOutput = self.forward(x)\n",
        "        return F.softmax(predictorOutput, dim=1)\n",
        "    \n",
        "    def trainLayer(self, dataloader, previousLayers):\n",
        "        for epoch in range(self.num_epochs):\n",
        "              criterion = nn.CrossEntropyLoss()\n",
        "              for i, data in enumerate(dataloader):\n",
        "                  originalInputs, labels = data\n",
        "                  originalInputs = originalInputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  inputs = originalInputs\n",
        "                  for previous in previousLayers:\n",
        "                      if isinstance(previous, nn.MaxPool2d) or isinstance(previous, nn.Flatten):\n",
        "                          inputs = previous.forward(inputs)\n",
        "                      else:\n",
        "                          inputs,_ = previous.forward(inputs)\n",
        "                  self.opt.zero_grad()\n",
        "                  layerOutput, predictorOutput = self.forward(inputs)\n",
        "                  layerLoss = criterion(predictorOutput, labels)\n",
        "                  # This is a local layer update, not a backprop through the net\n",
        "                  layerLoss.backward()\n",
        "                  self.opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6JCyA-52rD6"
      },
      "outputs": [],
      "source": [
        "# Helper function to dynamically compute the output size\n",
        "def conv2d_output_size(input_size, out_channels, padding, kernel_size, stride, dilation=None):\n",
        "    \"\"\"According to https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "    \"\"\"\n",
        "    if dilation is None:\n",
        "        dilation = (1, ) * 2\n",
        "    if isinstance(padding, int):\n",
        "        padding = (padding, ) * 2\n",
        "    if isinstance(kernel_size, int):\n",
        "        kernel_size = (kernel_size, ) * 2\n",
        "    if isinstance(stride, int):\n",
        "        stride = (stride, ) * 2\n",
        "\n",
        "    output_size = (\n",
        "        out_channels,\n",
        "        np.floor((input_size[1] + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) /\n",
        "                 stride[0] + 1).astype(int),\n",
        "        np.floor((input_size[2] + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) /\n",
        "                 stride[1] + 1).astype(int)\n",
        "    )\n",
        "    return output_size\n",
        "\n",
        "\n",
        "# A convolutional Layer for FF\n",
        "\n",
        "class FFConv2D(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 sampleInput,\n",
        "                 stride=1, padding=1, dilation=1, groups=1, \n",
        "                 num_epochs = 25, layer_lr = 0.001, num_classes = 10,\n",
        "                 bias=True, padding_mode='zeros', device=None, dtype=None):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, \n",
        "                        dilation, groups, bias, padding_mode, device, dtype)\n",
        "        self.opt = Adam(self.parameters(), lr=layer_lr)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.getandSetPredictorWeightShape(sampleInput, device)\n",
        "\n",
        "    def getandSetPredictorWeightShape(self, sampleInput, device):\n",
        "        convOutput = F.relu(super().forward(sampleInput.to(self.device)))\n",
        "        self.predictor = nn.Linear(convOutput.shape[1]*convOutput.shape[2]*convOutput.shape[3],\n",
        "                                   self.num_classes, \n",
        "                                   device=device)\n",
        "        self.predictor.requires_grad = False\n",
        "    \n",
        "    def conv_output_shape(self, h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
        "        if type(kernel_size) is not tuple:\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        h = floor( ((h_w[0] + (2 * pad) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n",
        "        w = floor( ((h_w[1] + (2 * pad) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n",
        "        return h, w\n",
        "\n",
        "    def forward(self, x):\n",
        "        convOutput = F.relu(super().forward(x))\n",
        "        predInput = convOutput.view(convOutput.size(0), -1)\n",
        "        predOutput = self.predictor(predInput)\n",
        "        return convOutput, predOutput\n",
        "    \n",
        "    def predict(self, x):\n",
        "        layerOutput, predictorOutput = self.forward(x)\n",
        "        return F.softmax(predictorOutput, dim=1)\n",
        "    \n",
        "    def trainLayer(self, dataloader, previousLayers):\n",
        "        for epoch in range(self.num_epochs):\n",
        "              criterion = nn.CrossEntropyLoss()\n",
        "              for i, data in enumerate(dataloader):\n",
        "                  originalInputs, labels = data\n",
        "                  originalInputs = originalInputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  inputs = originalInputs\n",
        "                  for previous in previousLayers:\n",
        "                      if isinstance(previous, nn.MaxPool2d) or isinstance(previous, nn.Flatten):\n",
        "                          inputs = previous.forward(inputs)\n",
        "                      else:\n",
        "                          inputs,_ = previous.forward(inputs)\n",
        "                  self.opt.zero_grad()\n",
        "                  layerOutput, predictorOutput = self.forward(inputs)\n",
        "                  layerLoss = criterion(predictorOutput, labels)\n",
        "                  # This is a local layer update, not a backprop through the net\n",
        "                  layerLoss.backward()\n",
        "                  self.opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D07KxZCDx9s"
      },
      "outputs": [],
      "source": [
        "\n",
        "# The overall FF Network\n",
        "class FFNet(torch.nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        sample_input = torch.rand(1,3,32,32).to(device)\n",
        "        self.conv1 = FFConv2D(3, 64, 3, sample_input, device=device)\n",
        "        conv1_output_eg, eg_preds = self.conv1.forward(sample_input)\n",
        "        pooledEg = self.pool.forward(conv1_output_eg)\n",
        "        self.conv2 = FFConv2D(64, 128, 3, pooledEg, device=device)\n",
        "        conv2_output_eg, eg_preds = self.conv2.forward(pooledEg)\n",
        "        pooledEg = self.pool.forward(conv2_output_eg)\n",
        "        self.conv3 = FFConv2D(128, 256, 3, pooledEg, device=device)\n",
        "        conv3_output_eg, eg_preds = self.conv3.forward(pooledEg)\n",
        "        self.conv4 = FFConv2D(256, 256, 3, conv3_output_eg, device=device)\n",
        "        conv4_output_eg, eg_preds = self.conv4.forward(conv3_output_eg)\n",
        "        pooledEg = self.pool.forward(conv4_output_eg)\n",
        "        self.conv5 = FFConv2D(256, 512, 3, pooledEg, device=device)\n",
        "        conv5_output_eg, eg_preds = self.conv5.forward(pooledEg)\n",
        "        self.conv6 = FFConv2D(512, 512, 3, conv5_output_eg, device=device)\n",
        "        conv6_output_eg, eg_preds = self.conv6.forward(conv5_output_eg)\n",
        "        pooledEg = self.pool.forward(conv6_output_eg)\n",
        "        self.conv7 = FFConv2D(512, 512, 3, pooledEg, device=device)\n",
        "        conv7_output_eg, eg_preds = self.conv7.forward(pooledEg)\n",
        "        self.conv8 = FFConv2D(512, 512, 3, conv7_output_eg, device=device)\n",
        "        conv8_output_eg, eg_preds = self.conv7.forward(conv7_output_eg)\n",
        "        pooledEg = self.pool.forward(conv8_output_eg)\n",
        "        self.fc1 = FFLinearLayer(pooledEg.flatten(start_dim=1).shape[1], 4096, device=device) # was 16*5*5\n",
        "        self.fc2 = FFLinearLayer(4096,4096, device=device) \n",
        "        self.fc3 = FFLinearLayer(4096,10, device=device)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.layers = [self.conv1, \n",
        "                       self.pool,\n",
        "                       self.conv2,\n",
        "                       self.pool,\n",
        "                       self.conv3,\n",
        "                       self.conv4,\n",
        "                       self.pool,\n",
        "                       self.conv5,\n",
        "                       self.conv6,\n",
        "                       self.pool,\n",
        "                       self.conv7,\n",
        "                       self.conv8,\n",
        "                       self.pool,\n",
        "                       self.flat, \n",
        "                       self.fc1, \n",
        "                       self.fc2, \n",
        "                       self.fc3]\n",
        "        self.trainableList = [self.conv1, \n",
        "                              self.conv2, \n",
        "                              self.conv3,\n",
        "                              self.conv4,\n",
        "                              self.conv5,\n",
        "                              self.conv6,\n",
        "                              self.conv7,\n",
        "                              self.conv8,\n",
        "                              self.fc1, \n",
        "                              self.fc2, \n",
        "                              self.fc3]\n",
        "    \n",
        "    def trainNet(self, dataloader):\n",
        "        for layer in range(len(self.layers)):\n",
        "            if self.layers[layer] not in self.trainableList:\n",
        "                print(\"Skipping untrainable layer \", layer + 1)\n",
        "            else:\n",
        "                print(\"Training Layer\", layer + 1)\n",
        "                previousLayers = self.layers[:layer]\n",
        "                self.layers[layer].trainLayer(dataloader, previousLayers)\n",
        "    \n",
        "    # Predict on a batch\n",
        "    def predict(self, x):\n",
        "        # get per layer logits\n",
        "        layerPreds = []\n",
        "        layerInput = x\n",
        "        for layer in self.layers:\n",
        "            if layer not in self.trainableList:\n",
        "                layerInput = layer.forward(layerInput)\n",
        "            else:\n",
        "                layerOutput, layerPred = layer.forward(layerInput)\n",
        "                # Get per layer softmax\n",
        "                layerPreds.append(F.softmax(layerPred, dim=1))\n",
        "                layerInput = layerOutput\n",
        "        layerPreds = torch.stack(layerPreds)\n",
        "        # Add up per layer softmax\n",
        "        combinedPred = torch.sum(layerPreds, dim=0)\n",
        "        finalPred = F.softmax(combinedPred, dim=1)\n",
        "        return finalPred\n",
        "    \n",
        "    # Predict on a batch (better)\n",
        "    def predictFinal(self, x):\n",
        "        # get per layer logits\n",
        "        layerPreds = []\n",
        "        layerInput = x\n",
        "        for layer in self.layers:\n",
        "            if layer not in self.trainableList:\n",
        "                layerInput = layer.forward(layerInput)\n",
        "            else:\n",
        "                layerOutput, layerPred = layer.forward(layerInput)\n",
        "                # Get per layer softmax\n",
        "                layerPreds.append(F.softmax(layerPred, dim=1))\n",
        "                layerInput = layerOutput\n",
        "        #layerPreds = torch.stack(layerPreds)\n",
        "        # Add up per layer softmax\n",
        "        #combinedPred = torch.sum(layerPreds, dim=0)\n",
        "        finalPred = layerPreds[-1] #F.softmax(combinedPred, dim=1)\n",
        "        return finalPred\n",
        "    \n",
        "    # Evaluate on loader\n",
        "    def evaluate(self, loader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                preds = self.predictFinal(inputs) #self.predict(inputs)\n",
        "                _, predicted = torch.max(preds, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        return correct/total\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "net = FFNet(device)"
      ],
      "metadata": {
        "id": "PTlgqdTEE5Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ILLSizeEstimator(object):\n",
        "\n",
        "    def __init__(self, model, input_size=(1,3,32,32), bits=32):\n",
        "        '''\n",
        "        Estimates the size of PyTorch models in memory\n",
        "        for a given input size\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        self.bits = bits\n",
        "        return\n",
        "\n",
        "    def get_parameter_sizes(self):\n",
        "        '''Get sizes of all parameters in `model`'''\n",
        "        mods = self.model.layers\n",
        "        print(len(mods))\n",
        "        sizes = []\n",
        "        predictors = []\n",
        "        \n",
        "        for i in range(len(mods)):\n",
        "            m = mods[i]\n",
        "            p = list(m.parameters())\n",
        "            if isinstance(m, FFConv2D) or isinstance(m, FFLinearLayer):\n",
        "              predictors.append(m.predictor.parameters())\n",
        "            else:\n",
        "              predictors.append(None)\n",
        "            for j in range(len(p)):\n",
        "                sizes.append(np.array(p[j].size()))\n",
        "        print(predictors)\n",
        "        # Add predictor of final layer\n",
        "        sizes.append(np.array(predictors[-1].size()))\n",
        "        param_sizes = sizes\n",
        "        return param_sizes\n",
        "\n",
        "    def get_output_sizes(self, active_layers):\n",
        "        '''Run sample input through each layer to get output sizes'''\n",
        "        input_ = torch.rand(self.input_size[0],self.input_size[1],\n",
        "                            self.input_size[2],self.input_size[3]).to(device)\n",
        "        mods = active_layers #self.model.layers #list(self.model.modules())\n",
        "        out_sizes = []\n",
        "        preds = None\n",
        "        for i in range(len(mods)):\n",
        "            m = mods[i]\n",
        "            res = m.forward(input_)\n",
        "            if type(res) == tuple:\n",
        "              out = res[0]\n",
        "              preds = res[1]\n",
        "            else:\n",
        "              out = res\n",
        "            out_sizes.append(np.array(out.size()))\n",
        "            input_ = out\n",
        "        if preds is not None:\n",
        "          out_sizes.append(np.array(preds.size()))\n",
        "        out_sizes = out_sizes\n",
        "        return out_sizes\n",
        "    \n",
        "    def get_param_sizes(self, active_layers):\n",
        "        mods = active_layers\n",
        "        #print(len(mods))\n",
        "        sizes = []\n",
        "        last_pred = None\n",
        "        \n",
        "        for i in range(len(mods)):\n",
        "            m = mods[i]\n",
        "            p = list(m.parameters())\n",
        "            if isinstance(m, FFConv2D) or isinstance(m, FFLinearLayer):\n",
        "              last_pred = m.predictor\n",
        "            for j in range(len(p)):\n",
        "              sizes.append(np.array(p[j].size()))\n",
        "\n",
        "        #gradient for BP\n",
        "        bp_size = sizes[-1]\n",
        "        \n",
        "        # Add predictor of final layer\n",
        "        p = list(last_pred.parameters())\n",
        "        for j in range(len(p)):\n",
        "            sizes.append(np.array(p[j].size()))\n",
        "\n",
        "        param_sizes = sizes\n",
        "        return param_sizes, bp_size\n",
        "\n",
        "    def calc_param_bits(self, param_sizes):\n",
        "        '''Calculate total number of bits to store `model` parameters'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(param_sizes)):\n",
        "            s = param_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        param_bits = total_bits\n",
        "        return param_bits\n",
        "    \n",
        "    def get_bit_sizes(self, arr):\n",
        "        total_bits = 0\n",
        "        for i in range(len(arr)):\n",
        "            s = arr[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        return total_bits\n",
        "\n",
        "    # Iterate through layers\n",
        "    # If is trainable - get static size, and double param size of last layer\n",
        "    def calc_max_bits(self):\n",
        "        input_bits = np.prod(np.array(self.input_size))*self.bits\n",
        "        all_layers = self.model.layers\n",
        "        sizes_bits = []\n",
        "        sizes_mb = []\n",
        "        for i in range(len(all_layers)):\n",
        "          if isinstance(all_layers[i], FFConv2D) or isinstance(all_layers[i], FFLinearLayer):\n",
        "            active_layers = all_layers[:i+1]\n",
        "            active_op_sizes = self.get_output_sizes(active_layers)\n",
        "            active_param_sizes, backprop_size = self.get_param_sizes(active_layers)\n",
        "            layer_bits = self.get_bit_sizes(active_op_sizes) + self.get_bit_sizes(active_param_sizes) + self.get_bit_sizes(backprop_size)\n",
        "            layer_mb = (layer_bits/8)/(1024**2)\n",
        "            sizes_bits.append(layer_bits)\n",
        "            sizes_mb.append(layer_mb)\n",
        "\n",
        "            \n",
        "        return sizes_bits, sizes_mb\n",
        "\n",
        "    def calc_forward_bits(self):\n",
        "        '''Calculate bits to store forward and backward pass'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.out_sizes)):\n",
        "            s = self.out_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.forward_bits = (total_bits)\n",
        "        return    \n",
        "    \n",
        "    def calc_backward_bits(self):\n",
        "        '''Calculate bits to store forward and backward pass'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.out_sizes)):\n",
        "            s = self.out_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.backward_bits = (total_bits)\n",
        "        return\n",
        "\n",
        "    def calc_input_bits(self):\n",
        "        '''Calculate bits to store input'''\n",
        "        self.input_bits = np.prod(np.array(self.input_size))*self.bits\n",
        "        return\n",
        "\n",
        "    def estimate_size(self):\n",
        "        '''Estimate model size in memory in megabytes and bits'''\n",
        "        self.get_parameter_sizes()\n",
        "        self.get_output_sizes()\n",
        "        self.calc_param_bits()\n",
        "        self.calc_forward_bits()\n",
        "        self.calc_backward_bits()\n",
        "        self.calc_input_bits()\n",
        "        final_total_output = self.param_bits + self.forward_bits + self.backward_bits #self.param_bits + self.forward_bits + self.backward_bits + self.input_bits\n",
        "\n",
        "        total_megabytes = (total/8)/(1024**2)\n",
        "        return total_megabytes, total"
      ],
      "metadata": {
        "id": "la4gc5fYLx6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizeEstimator = ILLSizeEstimator(net)"
      ],
      "metadata": {
        "id": "aOKQjlmEGbs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bits, mb = sizeEstimator.calc_max_bits()"
      ],
      "metadata": {
        "id": "kXQpQ7chH4Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max memory usage (ILL):\", np.max(mb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oYAd_Cvc3FS",
        "outputId": "95084a85-0bbc-40b1-9fda-8509c9653524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max memory usage (ILL): 114.18643188476562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "class SizeEstimatorBP(object):\n",
        "\n",
        "    def __init__(self, model, input_size=(1,3,32,32), bits=32):\n",
        "        '''\n",
        "        Estimates the size of PyTorch models in memory\n",
        "        for a given input size\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        self.bits = bits\n",
        "        self.gradient_sizes = 0\n",
        "        self.grad_bits =0 \n",
        "        return\n",
        "    \n",
        "    def get_gradient_sizes(self):\n",
        "        '''Get sizes of all gradients in `model`'''\n",
        "        mods = self.model.layers #list(self.model.modules())\n",
        "        print(len(mods))\n",
        "        sizes = []\n",
        "        for i in range(len(mods)):\n",
        "            m = mods[i]\n",
        "            p = list(m.parameters())\n",
        "            for j in range(len(p)):\n",
        "                if p[j].requires_grad:\n",
        "                  sizes.append(np.array(p[j].size()))\n",
        "\n",
        "        self.gradient_sizes = sizes\n",
        "        return\n",
        "\n",
        "    def get_parameter_sizes(self):\n",
        "        '''Get sizes of all parameters in `model`'''\n",
        "        mods = self.model.layers #list(self.model.modules())\n",
        "        print(len(mods))\n",
        "        sizes = []\n",
        "        \n",
        "        for i in range(len(mods)):\n",
        "            m = mods[i]\n",
        "            p = list(m.parameters())\n",
        "            for j in range(len(p)):\n",
        "                sizes.append(np.array(p[j].size()))\n",
        "\n",
        "        self.param_sizes = sizes\n",
        "        return\n",
        "\n",
        "    def get_output_sizes(self):\n",
        "        '''Run sample input through each layer to get output sizes'''\n",
        "        input_ = Variable(torch.FloatTensor(*self.input_size), volatile=True)\n",
        "        mods = self.model.layers #list(self.model.modules())\n",
        "        out_sizes = []\n",
        "        for i in range(len(mods)):\n",
        "            m = mods[i]\n",
        "            out = m(input_)\n",
        "            out_sizes.append(np.array(out.size()))\n",
        "            input_ = out\n",
        "\n",
        "        self.out_sizes = out_sizes\n",
        "        return\n",
        "\n",
        "    def calc_param_bits(self):\n",
        "        '''Calculate total number of bits to store `model` parameters'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.param_sizes)):\n",
        "            s = self.param_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.param_bits = total_bits\n",
        "        return\n",
        "\n",
        "    def calc_gradient_bits(self):\n",
        "        '''Calculate total number of bits to store `model` parameters'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.gradient_sizes)):\n",
        "            s = self.param_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.grad_bits = total_bits\n",
        "        return\n",
        "\n",
        "#     def calc_forward_backward_bits(self):\n",
        "#         '''Calculate bits to store forward and backward pass'''\n",
        "#         total_bits = 0\n",
        "#         for i in range(len(self.out_sizes)):\n",
        "#             s = self.out_sizes[i]\n",
        "#             bits = np.prod(np.array(s))*self.bits\n",
        "#             total_bits += bits\n",
        "#         # multiply by 2 for both forward AND backward\n",
        "#         self.forward_backward_bits = (total_bits*2)\n",
        "#         return\n",
        "    def calc_forward_bits(self):\n",
        "        '''Calculate bits to store forward and backward pass'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.out_sizes)):\n",
        "            s = self.out_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.forward_bits = (total_bits)\n",
        "        return    \n",
        "    \n",
        "    def calc_backward_bits(self):\n",
        "        '''Calculate bits to store forward and backward pass'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.out_sizes)):\n",
        "            s = self.out_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.backward_bits = (total_bits)\n",
        "        return\n",
        "\n",
        "    def calc_input_bits(self):\n",
        "        '''Calculate bits to store input'''\n",
        "        self.input_bits = np.prod(np.array(self.input_size))*self.bits\n",
        "        return\n",
        "\n",
        "    def to_mb(self, bitcount):\n",
        "      return (bitcount/8)/(1024**2)\n",
        "\n",
        "    def estimate_size(self):\n",
        "        '''Estimate model size in memory in megabytes and bits'''\n",
        "        self.get_parameter_sizes()\n",
        "        self.get_gradient_sizes()\n",
        "        self.get_output_sizes()\n",
        "        self.calc_param_bits()\n",
        "        self.calc_forward_bits()\n",
        "        self.calc_backward_bits()\n",
        "        self.calc_gradient_bits()\n",
        "        self.calc_input_bits()\n",
        "\n",
        "        param_mb = self.to_mb(self.param_bits)\n",
        "        print(\"Params:\", param_mb)\n",
        "\n",
        "        forward_mb = self.to_mb(self.forward_bits)\n",
        "        print(\"Forward:\", forward_mb)\n",
        "\n",
        "        #backward_mb = self.to_mb(self.backward_bits)\n",
        "        #print(\"Backward pass:\", backward_mb)\n",
        "\n",
        "        grad_mb = self.to_mb(self.grad_bits)\n",
        "        print(\"Gradients:\", grad_mb)\n",
        "\n",
        "        return param_mb + forward_mb + grad_mb"
      ],
      "metadata": {
        "id": "cdfA_2tBdC6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG11NetBP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = [nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=512, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=10)\n",
        "            ]"
      ],
      "metadata": {
        "id": "cRAZFcNxgDXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpnet = VGG11NetBP()\n"
      ],
      "metadata": {
        "id": "UaehfhiEggj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpsize_estimator = SizeEstimatorBP(bpnet)\n",
        "total = bpsize_estimator.estimate_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIuqA7a3gpZi",
        "outputId": "29cd696e-a151-4d7e-f444-575f8503d1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "27\n",
            "Params: 107.36087799072266\n",
            "Forward: 1.3398818969726562\n",
            "Gradients: 107.36087799072266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-121d06ae987e>:52: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  input_ = Variable(torch.FloatTensor(*self.input_size), volatile=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max usage:\", total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8XznuQ9hIbw",
        "outputId": "b50051eb-157b-4861-a3c4-44e333159430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max usage: 216.06163787841797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJN8h-DTha8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}